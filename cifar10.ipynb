{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from resnet_cifar10_ttq import resnet18\n",
    "from squeezenet import SqueezeNet\n",
    "from alexnet import AlexNet\n",
    "from vgg import VGG\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, test_batch_size):\n",
    "    normalize = transforms.Normalize((0.491399689874, 0.482158419622, 0.446530924224), (0.247032237587, 0.243485133253, 0.261587846975))\n",
    "    train_transform = transforms.Compose((transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=2), transforms.ToTensor(), normalize))\n",
    "    test_transform = transforms.Compose((transforms.ToTensor(), normalize))\n",
    "\n",
    "    loader_args = {'num_workers': 4}\n",
    "    if use_cuda:\n",
    "        loader_args.update({'pin_memory': True})\n",
    "\n",
    "    data_location = 'data/cifar10'\n",
    "\n",
    "    trainset = datasets.CIFAR10(root=data_location, train=True, download=True, transform=train_transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size=batch_size, **loader_args)\n",
    "\n",
    "    testset = datasets.CIFAR10(root=data_location, train=False, download=True, transform=test_transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size=test_batch_size, **loader_args)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    return trainloader, testloader, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 256\n",
    "test_batch_size = 1024\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-6\n",
    "log_interval = 20\n",
    "ttq = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if not use_cuda:\n",
    "    print('warning: cuda not available')\n",
    "    \n",
    "trainloader, testloader, classes = get_data(train_batch_size, test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SqueezeNet(version=1.1, num_classes=10, small_input=True, use_ttq=ttq)\n",
    "# model = resnet18(use_ttq=True)\n",
    "# model = AlexNet(use_ttq=True, num_classes=10)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model.load_state_dict(torch.load('models/squeezenet_cifar.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 0.736911\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 0.738652\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 0.738221\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 0.743175\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.738504\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 0.746025\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 0.744704\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 0.745836\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 0.744851\n",
      "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 0.748183\n",
      "26.78s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8427, Accuracy: 7202/10000 (72%)\n",
      "\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 0.781159\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 0.755777\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 0.746150\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 0.752310\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.752220\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 0.751435\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 0.750232\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 0.752298\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 0.750363\n",
      "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 0.751337\n",
      "26.72s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8367, Accuracy: 7273/10000 (73%)\n",
      "\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 0.711879\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 0.725581\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 0.718867\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 0.729284\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.728961\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 0.734681\n",
      "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 0.735226\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 0.739347\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 0.739584\n",
      "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 0.737464\n",
      "26.73s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8480, Accuracy: 7248/10000 (72%)\n",
      "\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 0.721552\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 0.726475\n",
      "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 0.728963\n",
      "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 0.728474\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.732249\n",
      "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 0.729927\n",
      "Train Epoch: 4 [35840/50000 (72%)]\tLoss: 0.727909\n",
      "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 0.731259\n",
      "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 0.730133\n",
      "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 0.728680\n",
      "26.75s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8408, Accuracy: 7298/10000 (73%)\n",
      "\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 0.725771\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 0.722809\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 0.710489\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 0.721658\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.725323\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 0.726524\n",
      "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 0.728178\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 0.732570\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 0.735739\n",
      "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 0.733651\n",
      "26.75s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8394, Accuracy: 7250/10000 (72%)\n",
      "\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 0.721189\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 0.719532\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 0.730656\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 0.728798\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.723146\n",
      "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 0.725687\n",
      "Train Epoch: 6 [35840/50000 (72%)]\tLoss: 0.728110\n",
      "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 0.727799\n",
      "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 0.726343\n",
      "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.724096\n",
      "26.72s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8260, Accuracy: 7317/10000 (73%)\n",
      "\n",
      "Train Epoch: 7 [5120/50000 (10%)]\tLoss: 0.725020\n",
      "Train Epoch: 7 [10240/50000 (20%)]\tLoss: 0.713032\n",
      "Train Epoch: 7 [15360/50000 (31%)]\tLoss: 0.710629\n",
      "Train Epoch: 7 [20480/50000 (41%)]\tLoss: 0.706499\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.713883\n",
      "Train Epoch: 7 [30720/50000 (61%)]\tLoss: 0.715132\n",
      "Train Epoch: 7 [35840/50000 (72%)]\tLoss: 0.718966\n",
      "Train Epoch: 7 [40960/50000 (82%)]\tLoss: 0.718345\n",
      "Train Epoch: 7 [46080/50000 (92%)]\tLoss: 0.718419\n",
      "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.717003\n",
      "26.72s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8581, Accuracy: 7210/10000 (72%)\n",
      "\n",
      "Train Epoch: 8 [5120/50000 (10%)]\tLoss: 0.704714\n",
      "Train Epoch: 8 [10240/50000 (20%)]\tLoss: 0.720157\n",
      "Train Epoch: 8 [15360/50000 (31%)]\tLoss: 0.725417\n",
      "Train Epoch: 8 [20480/50000 (41%)]\tLoss: 0.723212\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.718540\n",
      "Train Epoch: 8 [30720/50000 (61%)]\tLoss: 0.720543\n",
      "Train Epoch: 8 [35840/50000 (72%)]\tLoss: 0.717229\n",
      "Train Epoch: 8 [40960/50000 (82%)]\tLoss: 0.715379\n",
      "Train Epoch: 8 [46080/50000 (92%)]\tLoss: 0.715914\n",
      "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.713179\n",
      "26.71s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8621, Accuracy: 7179/10000 (72%)\n",
      "\n",
      "Train Epoch: 9 [5120/50000 (10%)]\tLoss: 0.706704\n",
      "Train Epoch: 9 [10240/50000 (20%)]\tLoss: 0.715868\n",
      "Train Epoch: 9 [15360/50000 (31%)]\tLoss: 0.713455\n",
      "Train Epoch: 9 [20480/50000 (41%)]\tLoss: 0.711632\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.705251\n",
      "Train Epoch: 9 [30720/50000 (61%)]\tLoss: 0.706864\n",
      "Train Epoch: 9 [35840/50000 (72%)]\tLoss: 0.709616\n",
      "Train Epoch: 9 [40960/50000 (82%)]\tLoss: 0.707527\n",
      "Train Epoch: 9 [46080/50000 (92%)]\tLoss: 0.709331\n",
      "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.708391\n",
      "26.74s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8534, Accuracy: 7275/10000 (73%)\n",
      "\n",
      "Train Epoch: 10 [5120/50000 (10%)]\tLoss: 0.726989\n",
      "Train Epoch: 10 [10240/50000 (20%)]\tLoss: 0.698636\n",
      "Train Epoch: 10 [15360/50000 (31%)]\tLoss: 0.702400\n",
      "Train Epoch: 10 [20480/50000 (41%)]\tLoss: 0.702093\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.700513\n",
      "Train Epoch: 10 [30720/50000 (61%)]\tLoss: 0.696165\n",
      "Train Epoch: 10 [35840/50000 (72%)]\tLoss: 0.698095\n",
      "Train Epoch: 10 [40960/50000 (82%)]\tLoss: 0.699276\n",
      "Train Epoch: 10 [46080/50000 (92%)]\tLoss: 0.702128\n",
      "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.704571\n",
      "26.74s/epoch\n",
      "\n",
      "Test set: Average loss: 0.8143, Accuracy: 7346/10000 (73%)\n",
      "\n",
      "Accuracy of plane : 50 %\n",
      "Accuracy of   car : 100 %\n",
      "Accuracy of  bird :  0 %\n",
      "Accuracy of   cat : 57 %\n",
      "Accuracy of  deer : 100 %\n",
      "Accuracy of   dog : 75 %\n",
      "Accuracy of  frog : 50 %\n",
      "Accuracy of horse : 100 %\n",
      "Accuracy of  ship : 100 %\n",
      "Accuracy of truck : 83 %\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_total = 0\n",
    "    # correct = 0\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        # pred = outputs.data.max(1, keepdim=True)[1]\n",
    "        # correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        running_total += len(inputs)\n",
    "        num = i + 1\n",
    "        if num % log_interval == 0 or num == len(trainloader):\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, running_total, len(trainloader.dataset),\n",
    "                100 * running_total / len(trainloader.dataset), running_loss / num))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    running_loss = 0\n",
    "    for inputs, labels in testloader:\n",
    "        if use_cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        outputs = model(inputs)\n",
    "        running_loss += criterion(outputs, labels, size_average=False).data[0]\n",
    "        pred = outputs.data.max(1, keepdim=True)[1] # get the index of the max\n",
    "        correct += pred.eq(labels.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        running_loss / len(testloader.dataset), correct, len(testloader.dataset),\n",
    "        100 * correct / len(testloader.dataset)))\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start = time.time()\n",
    "    train(epoch)\n",
    "    delta = time.time() - start\n",
    "    print('{:.2f}s/epoch'.format(delta))\n",
    "    torch.save(model.state_dict(), 'model.pth')\n",
    "    test()\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = model(Variable(images.cuda(), volatile=True))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels.cuda()).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Resnet18\n",
    "## Train loss: 0.508\n",
    "## Test Loss: 0.69   Test Accuracy: 0.77\n",
    "\n",
    "# Resnet18 TTQ\n",
    "## Train loss: 0.30\n",
    "## Test Loss: 0.49   Test Accuracy: 0.83\n",
    "\n",
    "# SqueezeNet\n",
    "## Train loss: 0.704571\n",
    "## Test loss: 0.8143    Test Accuracy: 0.73"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
